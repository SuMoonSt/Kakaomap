{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "음식점정보 CSV전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 작업경로 초기화\n",
    "def init_folder(download_path):\n",
    "    if os.path.exists(download_path):\n",
    "    # 폴더가 존재하면 내용을 모두 삭제\n",
    "        for filename in os.listdir(download_path):\n",
    "            file_path = os.path.join(download_path, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                logging.warning(f'Failed to delete {file_path}. Reason: {e}')\n",
    "    else:\n",
    "        # 폴더가 존재하지 않으면 새로 생성\n",
    "        os.makedirs(download_path)\n",
    "\n",
    "    logging.info(\"'downloads' 폴더가 정리되었습니다.\")\n",
    "\n",
    "# 다운로드 폴더와 원하는 파일 이름 설정\n",
    "def downloadCsv(download_url, download_path):\n",
    "\n",
    "    input_fieldcode = \"TRDSTATENM\" #(영업상태명) 필드코드\n",
    "    input_text = \"영업\"\n",
    "\n",
    "    # Chrome WebDriver 설정\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "        \"download.default_directory\": download_path,\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"download.directory_upgrade\": True,\n",
    "        \"safebrowsing.enabled\": True,\n",
    "        \"profile.default_content_settings.popups\": 0\n",
    "    })\n",
    "\n",
    "    # WebDriver 초기화\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # 웹페이지 열기\n",
    "    driver.get(download_url)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    try:\n",
    "        select_element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"selt_filterCol\"))\n",
    "    )\n",
    "        select = Select(select_element)\n",
    "        select.select_by_value(input_fieldcode)\n",
    "        get_fieldcode = select_element.get_attribute('value')\n",
    "        if get_fieldcode == input_fieldcode:\n",
    "            logging.info(f\"{input_fieldcode} 값이 정상적으로 입력되었습니다.\")\n",
    "        else:\n",
    "            logging.warning(f\"값이 올바르게 입력되지 않았습니다. 예상값: {input_fieldcode}, 실제값: {get_fieldcode}\")        \n",
    "\n",
    "        text_element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"txtFilter\"))\n",
    "        )\n",
    "        text_element.clear()\n",
    "        text_element.send_keys(input_text)\n",
    "        get_text = text_element.get_attribute('value')\n",
    "        if get_text == input_text:\n",
    "            logging.info(f\"{input_text} 값이 정상적으로 입력되었습니다.\")\n",
    "        else:\n",
    "            logging.warning(f\"값이 올바르게 입력되지 않았습니다. 예상값: {input_text}, 실제값: {get_text}\")\n",
    "\n",
    "        # '조회' 버튼 찾기 및 클릭\n",
    "        inquire_button = driver.find_element(By.XPATH, \"//button[@class='btn-base-s'][.//span[text()='조회']]\")\n",
    "        inquire_button.click()\n",
    "    \n",
    "        time.sleep(3)\n",
    "\n",
    "        # 'CSV 내려받기' 버튼 찾기 및 클릭\n",
    "        csv_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"btnCsv\"))\n",
    "        )\n",
    "        csv_button.click()\n",
    "\n",
    "        # 알림 창 처리\n",
    "        try:\n",
    "            WebDriverWait(driver, 5).until(EC.alert_is_present())\n",
    "            alert = driver.switch_to.alert\n",
    "            logging.info(f\"알림 메시지: {alert.text}\")\n",
    "            alert.accept()\n",
    "        except:\n",
    "            logging.warning(\"알림 창이 나타나지 않았습니다.\")\n",
    "\n",
    "        logging.info(\"CSV 파일 다운로드가 시작되었습니다.\")\n",
    "\n",
    "        csv_files = glob.glob(os.path.join(download_path, \"*.csv\"))\n",
    "        if csv_files:\n",
    "            logging.info(f\"CSV 파일 다운로드가 완료되었습니다: {csv_files[0]}\")\n",
    "        else:\n",
    "            logging,Warning(\"CSV 파일 다운로드가 실패했거나 아직 완료되지 않았습니다.\")\n",
    "\n",
    "    # 다운로드 완료 대기\n",
    "        time.sleep(3)  # 필요에 따라 시간 조정\n",
    "\n",
    "    except UnexpectedAlertPresentException as e:\n",
    "        logging.warning(f\"예상치 못한 알림 창 발생: {e.alert_text}\")\n",
    "        driver.switch_to.alert.accept()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"오류 발생: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # 브라우저 종료\n",
    "        driver.quit()\n",
    "    return(csv_files[0])\n",
    "\n",
    "# csv파일을 읽어서 df생성\n",
    "def read_csv(csv_name):\n",
    "    df = pd.DataFrame()\n",
    "    encodings = ['utf-8', 'cp949', 'euc-kr']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_name, \n",
    "                             usecols=['관리번호', '전화번호', '지번주소', '도로명주소', '사업장명', '업태구분명'],\n",
    "                             dtype={'관리번호': str, '전화번호': str, '지번주소': str, '도로명주소': str, '사업장명': str, '업태구분명': str},\n",
    "                             encoding=encoding)\n",
    "            logging.info(f\"파일을 {encoding} 인코딩으로 성공적으로 읽었습니다.\")\n",
    "            # print(df.head())  # 데이터 확인\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"{encoding} 인코딩으로 읽기 실패: {e}\")\n",
    "    \n",
    "    logging.warning(\"모든 인코딩 시도 실패\")\n",
    "    return None\n",
    "\n",
    "def csv_main():\n",
    "    download_url = \"https://data.seoul.go.kr/dataList/OA-18665/S/1/datasetView.do\"\n",
    "    download_path = os.path.join(os.getcwd(), \"downloads\") #현재 작업 디렉토리(os.getcwd())\n",
    "\n",
    "    init_folder(download_path)\n",
    "    csv_name = downloadCsv(download_url,download_path)\n",
    "    #csv_name = glob.glob(os.path.join(download_path, \"*.csv\"))[0]\n",
    "    csv_data = read_csv(csv_name)\n",
    "    if csv_data is not None:\n",
    "        logging.info(f\"총 {len(csv_data)} 개의 행이 로드되었습니다.\")\n",
    "    else:\n",
    "        logging.warning(\"CSV 파일 읽기에 실패했습니다.\")\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "카카오맵에서 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_restaurant_kakao(driver, item):\n",
    "    driver.get(\"https://map.kakao.com/\")\n",
    "    searchbox = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//input[@id='search.keyword.query']\"))\n",
    "    )\n",
    "    searchbox.clear()\n",
    "    searchbox.send_keys(item)\n",
    "    get_text = searchbox.get_attribute('value')\n",
    "    if get_text != item:\n",
    "        logging.warning(f\"값이 올바르게 입력되지 않았습니다. 예상값: {item}, 실제값: {get_text}\")\n",
    "\n",
    "    searchbutton = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[@id='search.keyword.submit']\"))\n",
    "    )\n",
    "    driver.execute_script(\"arguments[0].click();\", searchbutton)\n",
    "    #searchbutton.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "def extract_data(driver):\n",
    "    result = {}\n",
    "    base_selector = \"#info\\\\.search\\\\.place\\\\.list > li:nth-child(1)\"\n",
    "    selectors = {\n",
    "        'href': f\"{base_selector} > div.info_item > div.contact.clickArea > a.moreview\",\n",
    "        'rating': f\"{base_selector} > div.rating.clickArea > span.score > em\",\n",
    "        'review': f\"{base_selector} > div.rating.clickArea > span.score > a\",\n",
    "        'blog_review': f\"{base_selector} > div.rating.clickArea > a > em\"\n",
    "    }\n",
    "    for key, selector in selectors.items():\n",
    "            try:\n",
    "                element = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "                )\n",
    "                if key == 'href':\n",
    "                    value = element.get_attribute(\"href\")\n",
    "                elif key == 'rating':\n",
    "                    try:\n",
    "                        value = float(element.text)\n",
    "                    except:\n",
    "                        value = 0.0\n",
    "                elif key == 'review':\n",
    "                    try:\n",
    "                        value = int(element.text.replace(\"건\", \"\"))\n",
    "                    except:\n",
    "                        value = 0\n",
    "                elif key == 'blog_review':\n",
    "                    try:\n",
    "                        value = int(element.text)\n",
    "                    except:\n",
    "                        value = 0\n",
    "                \n",
    "                result[key] = value\n",
    "                logging.info(f\"추출된 {key} 값: {value}\")\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"{key} 요소를 찾을 수 없습니다: {str(e)}\")\n",
    "                result[key] = None\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_reviews(driver, shop_ID, shop_name, result, latest_review_ids):\n",
    "    now = datetime.now()\n",
    "    now_date = now.strftime(\"%Y.%m.%d\")\n",
    "    reviewCount = int(result[\"review\"])\n",
    "    url = result[\"href\"]\n",
    "    review_df = pd.DataFrame(columns=[\"review_id\", \"user_id\", \"user_name\", \"shop_id\", \"shop_name\", \"content\", \"write_date\", \"crawl_date\", \"review_ratings\",])\n",
    "    user_info_df = pd.DataFrame(columns=[\"UserID\", \"UserName\", \"Reviews\", \"Ratings\",])\n",
    "    latest_review_id = int(latest_review_ids.get(int(shop_ID), 0))\n",
    "\n",
    "    if reviewCount == 0:\n",
    "        logging.info(\"리뷰가 없습니다.\")\n",
    "        return review_df, user_info_df\n",
    "\n",
    "    logging.info(\"리뷰 존재\")\n",
    "    try:\n",
    "        driver.execute_script('window.open(\"' + url + '\", \"_blank\");')\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            lambda driver: driver.execute_script('return document.readyState') == 'complete'\n",
    "        )\n",
    "        while True:\n",
    "            try:\n",
    "                next_page = WebDriverWait(driver, 5).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, \"#mArticle > div.cont_evaluation > div.evaluation_review > a\"))\n",
    "                )\n",
    "                if next_page.text == \"후기 더보기\":\n",
    "                    next_page.click()\n",
    "                    time.sleep(0.5)\n",
    "                else:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"오류 발생: {e}\")\n",
    "                break\n",
    "\n",
    "        # WebDriverWait(driver, 10).until(\n",
    "        #     EC.presence_of_element_located((By.CSS_SELECTOR, '.list_evaluation > li'))\n",
    "        # )\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        review_lists = soup.select('.list_evaluation > li')\n",
    "\n",
    "        for review in review_lists:\n",
    "            try:\n",
    "                review_id = int(review.get('data-id'))\n",
    "                if review_id > latest_review_id:\n",
    "                    review_data = extract_review_data(review, shop_ID, shop_name, now_date)\n",
    "                    user_info = extract_user_info(review, now_date)\n",
    "\n",
    "                    if review_data and any(review_data.values()):\n",
    "                        review_data_df = pd.DataFrame([review_data])\n",
    "                        if not review_data_df.empty:\n",
    "                            review_df = pd.concat([review_df, review_data_df], ignore_index=True)\n",
    "\n",
    "                    if user_info and any(user_info.values()): # user_info가 비어있지 않고 값이 있는 경우에만 연결\n",
    "                        user_data_df = pd.DataFrame([user_info])\n",
    "                        if not user_data_df.empty:\n",
    "                            user_info_df = pd.concat([user_info_df, user_data_df], ignore_index=True)\n",
    "\n",
    "                else:\n",
    "                    logging.info(f\"리뷰 ID {review_id}부터는 이미 수집되었습니다. 건너뜁니다.\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"리뷰 페이지 접근 중 오류 발생: {e}\")\n",
    "    finally:\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    return review_df, user_info_df\n",
    "\n",
    "def extract_review_data(review, shop_ID, shop_name, now_date):\n",
    "    user_review = review.select_one('.txt_comment > span').text\n",
    "    user_name = review.select_one('.txt_username').text\n",
    "    rating_style = review.select_one('.ico_star.inner_star').get(\"style\")\n",
    "    rating = float(re.findall(r'\\d+', rating_style)[0])/20\n",
    "    user_id = review.get('data-userid')\n",
    "    timestamp = review.select_one(' div > span.time_write').text\n",
    "    \n",
    "    return {\n",
    "        \"review_id\": int(review.get('data-id')),\n",
    "        \"user_id\": int(user_id),\n",
    "        \"user_name\": user_name,\n",
    "        \"shop_id\": int(shop_ID),\n",
    "        \"shop_name\": shop_name,\n",
    "        \"content\": user_review,\n",
    "        \"write_date\": timestamp,\n",
    "        \"crawl_date\": now_date,\n",
    "        \"review_ratings\": rating,\n",
    "        #\"LikePoint\": likepoint_string,\n",
    "    }\n",
    "\n",
    "def extract_user_info(review, now_date):\n",
    "    user_id = int(review.get('data-userid'))\n",
    "    user_name = review.select_one('.txt_username').text\n",
    "    user_info_div = review.find('div', class_='unit_info')\n",
    "    review_count = int(user_info_div.find('span', class_='txt_item', string='후기').find_next_sibling('span', class_='txt_desc').text.replace(\",\", \"\"))\n",
    "    rating_avg = float(user_info_div.find('span', class_='txt_item', string='별점평균').find_next_sibling('span', class_='txt_desc').text)\n",
    "\n",
    "    return {\n",
    "        \"user_id\": user_id,\n",
    "        \"user_name\": user_name,\n",
    "        \"stnd_ratings\": rating_avg,\n",
    "        \"total_reviews_cnt\": review_count,\n",
    "        \"insert_date\": now_date,\n",
    "        \"update_date\": now_date,\n",
    "    }\n",
    "\n",
    "def extract_main(items):\n",
    "    latest_review_ids = get_latest_review_ids()\n",
    "    driver = initialize_driver()\n",
    "    all_reviews = pd.DataFrame()\n",
    "    all_users = pd.DataFrame()\n",
    "\n",
    "    for shop_ID, shop_name in tqdm(items, desc=\"식당 처리 중\"):\n",
    "        search_restaurant_kakao(driver, shop_name)\n",
    "        if len(driver.find_elements(By.XPATH, \"//a[@class='moreview']\")) == 1:\n",
    "            logging.info(f'{shop_name}: 식당 존재')\n",
    "            result = extract_data(driver)\n",
    "            review_df, user_info_df = get_reviews(driver, shop_ID, shop_name, result, latest_review_ids)\n",
    "            \"\"\" 빈 DataFrame이나 모든 값이 NA인 행을 처리 \"\"\"\n",
    "            if not review_df.empty:\n",
    "                review_df = review_df.dropna(how='all')\n",
    "                all_reviews = pd.concat([all_reviews, review_df], ignore_index=True)\n",
    "            if not user_info_df.empty:\n",
    "                user_info_df = user_info_df.dropna(how='all')\n",
    "                all_users = pd.concat([all_users, user_info_df], ignore_index=True)\n",
    "        else:\n",
    "            logging.warning(f'{shop_name}: 식당이 존재하지 않거나 검색결과가 하나가 아님')\n",
    "\n",
    "    driver.quit()\n",
    "    return all_reviews, all_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터베이스 연결 함수\n",
    "def get_db_connection():\n",
    "\n",
    "\n",
    "def insert_reviews_to_db(reviews_df):\n",
    "    try:\n",
    "        engine = get_db_connection()\n",
    "        with engine.connect() as connection:\n",
    "            for _, row in reviews_df.iterrows():\n",
    "                insert_query = text(\"\"\"\n",
    "                INSERT INTO kakaomap_review \n",
    "                (review_id, user_id, user_name, shop_id, shop_name, content, write_date, crawl_date, review_ratings)\n",
    "                VALUES (:review_id, :user_id, :user_name, :shop_id, :shop_name, :content, :write_date, :crawl_date, :review_ratings)\n",
    "                \"\"\")\n",
    "                \n",
    "                write_date = row['write_date'].replace('.', '')\n",
    "                crawl_date = row['crawl_date'].replace('.', '')\n",
    "                \n",
    "                values = {\n",
    "                    \"review_id\": row['review_id'],\n",
    "                    \"user_id\": row['user_id'],\n",
    "                    \"user_name\": row['user_name'],\n",
    "                    \"shop_id\": row['shop_id'],\n",
    "                    \"shop_name\": row['shop_name'],\n",
    "                    \"content\": row['content'],\n",
    "                    \"write_date\": write_date,\n",
    "                    \"crawl_date\": crawl_date,\n",
    "                    \"review_ratings\": row['review_ratings']\n",
    "                }\n",
    "                \n",
    "                connection.execute(insert_query, values)\n",
    "            \n",
    "            connection.commit()\n",
    "        \n",
    "        logging.info(f\"{len(reviews_df)} 개의 리뷰가 성공적으로 삽입되었습니다.\")\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(f\"데이터베이스 오류: {e}\")\n",
    "    finally:\n",
    "        logging.info(\"데이터베이스 작업이 완료되었습니다.\")\n",
    "\n",
    "def get_latest_review_ids():\n",
    "    try:\n",
    "        engine = get_db_connection()\n",
    "        with engine.connect() as connection:\n",
    "            query = \"SELECT shop_id, MAX(review_id) AS max_review_id FROM kakaomap_review GROUP BY shop_id\"\n",
    "            df = pd.read_sql(query, connection)\n",
    "            logging.info(f\"최신 리뷰 ID 조회 결과:\\n{df}\")\n",
    "            \n",
    "        return df.set_index('shop_id')['max_review_id'].to_dict()\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(f\"데이터베이스 오류: {e}\")\n",
    "    finally:\n",
    "        logging.info(\"데이터베이스 작업이 완료되었습니다.\")\n",
    "    return {}\n",
    "\n",
    "def insert_users_to_db(user_df):\n",
    "    try:\n",
    "        engine = get_db_connection()\n",
    "        with engine.connect() as connection:\n",
    "            for _, row in user_df.iterrows():\n",
    "                insert_query = text(\"\"\"\n",
    "                INSERT INTO kakaomap_user \n",
    "                (user_id, user_name, stnd_ratings, total_reviews_cnt, insert_date, update_date)\n",
    "                VALUES (:user_id, :user_name, :stnd_ratings, :total_reviews_cnt, :insert_date, :update_date)\n",
    "                ON DUPLICATE KEY UPDATE\n",
    "                user_name = VALUES(user_name),\n",
    "                stnd_ratings = VALUES(stnd_ratings),\n",
    "                total_reviews_cnt = VALUES(total_reviews_cnt),\n",
    "                update_date = VALUES(update_date)\n",
    "                \"\"\")\n",
    "                \n",
    "                insert_date = row['insert_date'].replace('.', '')\n",
    "                update_date = row['update_date'].replace('.', '')\n",
    "                \n",
    "                values = {\n",
    "                    \"user_id\": row['user_id'],\n",
    "                    \"user_name\": row['user_name'],\n",
    "                    \"stnd_ratings\": row['stnd_ratings'],\n",
    "                    \"total_reviews_cnt\": row['total_reviews_cnt'],\n",
    "                    \"insert_date\": insert_date,\n",
    "                    \"update_date\": update_date,\n",
    "                }\n",
    "                \n",
    "                connection.execute(insert_query, values)\n",
    "            \n",
    "            connection.commit()\n",
    "        \n",
    "        logging.info(f\"{len(user_df)} 개의 리뷰가 성공적으로 삽입되었습니다.\")\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(f\"데이터베이스 오류: {e}\")\n",
    "    finally:\n",
    "        logging.info(\"데이터베이스 작업이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"웹드라이버 초기화\"\"\"\n",
    "def initialize_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # 헤드리스 모드 실행 (선택적)\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def main():\n",
    "    csv_data = csv_main()\n",
    "    # 실행\n",
    "    region = \"마포구\"\n",
    "    # DataFrame에서 '관리번호'와 '사업장명' 열만 추출\n",
    "    extracted_data = csv_data.head(8)[['관리번호', '사업장명']]\n",
    "    # '관리번호' \"-\" 키워드 제거\n",
    "    extracted_data['관리번호'] = extracted_data['관리번호'].apply(lambda x: x.replace(\"-\",\"\")[7:])\n",
    "    # '사업장명' 앞에 \"마포구\" 키워드 추가\n",
    "    extracted_data['사업장명'] = extracted_data['사업장명'].apply(lambda x: f\"{region} {x}\")\n",
    "    # '관리번호'와 수정된 '사업장명'을 리스트로 변환\n",
    "    result_list = extracted_data.values.tolist()\n",
    "    # top_5_rows = [f\"{region} {str(value)}\" for value in csv_data.head(2)['사업장명'].tolist()]\n",
    "    try:\n",
    "        reviews, users = extract_main(result_list)\n",
    "        insert_reviews_to_db(reviews)\n",
    "        insert_users_to_db(users)\n",
    "        logging.info(\"데이터 추출 및 삽입이 성공적으로 완료되었습니다.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"데이터 처리 중 오류 발생: {e}\")\n",
    "    finally:\n",
    "        logging.info(\"프로그램 실행이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 13:51:39,509 - INFO - 'downloads' 폴더가 정리되었습니다.\n",
      "2024-09-10 13:51:49,923 - INFO - TRDSTATENM 값이 정상적으로 입력되었습니다.\n",
      "2024-09-10 13:51:50,115 - INFO - 영업 값이 정상적으로 입력되었습니다.\n",
      "2024-09-10 13:51:58,651 - WARNING - 알림 창이 나타나지 않았습니다.\n",
      "2024-09-10 13:51:58,652 - INFO - CSV 파일 다운로드가 시작되었습니다.\n",
      "2024-09-10 13:51:58,653 - INFO - CSV 파일 다운로드가 완료되었습니다: c:\\Start\\python_basic\\KakaoMap\\downloads\\서울시 마포구 일반음식점 인허가 정보.csv\n",
      "2024-09-10 13:52:08,021 - WARNING - utf-8 인코딩으로 읽기 실패: 'utf-8' codec can't decode byte 0xb0 in position 0: invalid start byte\n",
      "2024-09-10 13:52:08,078 - INFO - 파일을 cp949 인코딩으로 성공적으로 읽었습니다.\n",
      "2024-09-10 13:52:08,079 - INFO - 총 8234 개의 행이 로드되었습니다.\n",
      "2024-09-10 13:52:09,488 - INFO - 최신 리뷰 ID 조회 결과:\n",
      "        shop_id  max_review_id\n",
      "0  1.011971e+11       10572330\n",
      "1  1.011973e+11       10025393\n",
      "2  1.011976e+11        8031798\n",
      "3  1.011976e+11       10225080\n",
      "2024-09-10 13:52:09,492 - INFO - 데이터베이스 작업이 완료되었습니다.\n",
      "2024-09-10 13:52:09,492 - INFO - ====== WebDriver manager ======\n",
      "2024-09-10 13:52:10,571 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-09-10 13:52:10,901 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-09-10 13:52:11,239 - INFO - Driver [C:\\Users\\moon\\.wdm\\drivers\\chromedriver\\win64\\128.0.6613.119\\chromedriver-win32/chromedriver.exe] found in cache\n",
      "식당 처리 중:   0%|          | 0/8 [00:00<?, ?it/s]2024-09-10 13:52:27,177 - INFO - 마포구 부영각: 식당 존재\n",
      "2024-09-10 13:52:27,195 - INFO - 추출된 href 값: https://place.map.kakao.com/1793606499\n",
      "2024-09-10 13:52:27,219 - INFO - 추출된 rating 값: 0.0\n",
      "2024-09-10 13:52:27,243 - INFO - 추출된 review 값: 0\n",
      "2024-09-10 13:52:27,265 - INFO - 추출된 blog_review 값: 0\n",
      "2024-09-10 13:52:27,267 - INFO - 리뷰가 없습니다.\n",
      "식당 처리 중:  12%|█▎        | 1/8 [00:14<01:43, 14.72s/it]2024-09-10 13:52:30,147 - INFO - 마포구 태순집: 식당 존재\n",
      "2024-09-10 13:52:30,160 - INFO - 추출된 href 값: https://place.map.kakao.com/10102045\n",
      "2024-09-10 13:52:30,177 - INFO - 추출된 rating 값: 4.0\n",
      "2024-09-10 13:52:30,194 - INFO - 추출된 review 값: 12\n",
      "2024-09-10 13:52:30,209 - INFO - 추출된 blog_review 값: 17\n",
      "2024-09-10 13:52:30,212 - INFO - 리뷰 존재\n",
      "2024-09-10 13:52:32,296 - INFO - 리뷰 ID 10572330는 이미 수집되었습니다. 건너뜁니다.\n",
      "식당 처리 중:  25%|██▌       | 2/8 [00:19<00:54,  9.06s/it]2024-09-10 13:52:35,361 - INFO - 마포구 마포옥하우스: 식당 존재\n",
      "2024-09-10 13:52:35,379 - INFO - 추출된 href 값: https://place.map.kakao.com/10344284\n",
      "2024-09-10 13:52:35,398 - INFO - 추출된 rating 값: 0.0\n",
      "2024-09-10 13:52:35,416 - INFO - 추출된 review 값: 0\n",
      "2024-09-10 13:52:35,432 - INFO - 추출된 blog_review 값: 246\n",
      "2024-09-10 13:52:35,434 - INFO - 리뷰가 없습니다.\n",
      "식당 처리 중:  38%|███▊      | 3/8 [00:22<00:31,  6.33s/it]2024-09-10 13:52:49,141 - WARNING - 마포구 도화곱창: 식당이 존재하지 않거나 검색결과가 하나가 아님\n",
      "식당 처리 중:  50%|█████     | 4/8 [00:36<00:36,  9.24s/it]2024-09-10 13:53:03,125 - INFO - 마포구 조박집투: 식당 존재\n",
      "2024-09-10 13:53:03,135 - INFO - 추출된 href 값: https://place.map.kakao.com/8083800\n",
      "2024-09-10 13:53:03,150 - INFO - 추출된 rating 값: 3.6\n",
      "2024-09-10 13:53:03,167 - INFO - 추출된 review 값: 16\n",
      "2024-09-10 13:53:03,183 - INFO - 추출된 blog_review 값: 30\n",
      "2024-09-10 13:53:03,185 - INFO - 리뷰 존재\n",
      "2024-09-10 13:53:05,737 - INFO - 리뷰 ID 10025393는 이미 수집되었습니다. 건너뜁니다.\n",
      "식당 처리 중:  62%|██████▎   | 5/8 [00:53<00:35, 11.91s/it]2024-09-10 13:53:08,685 - WARNING - 마포구 외백: 식당이 존재하지 않거나 검색결과가 하나가 아님\n",
      "식당 처리 중:  75%|███████▌  | 6/8 [00:56<00:17,  8.85s/it]2024-09-10 13:53:11,425 - INFO - 마포구 조마루뼈다귀마포점: 식당 존재\n",
      "2024-09-10 13:53:11,439 - INFO - 추출된 href 값: https://place.map.kakao.com/11160343\n",
      "2024-09-10 13:53:11,453 - INFO - 추출된 rating 값: 2.5\n",
      "2024-09-10 13:53:11,470 - INFO - 추출된 review 값: 4\n",
      "2024-09-10 13:53:11,483 - INFO - 추출된 blog_review 값: 9\n",
      "2024-09-10 13:53:11,485 - INFO - 리뷰 존재\n",
      "2024-09-10 13:53:12,767 - INFO - 리뷰 ID 8031798는 이미 수집되었습니다. 건너뜁니다.\n",
      "식당 처리 중:  88%|████████▊ | 7/8 [01:00<00:07,  7.31s/it]2024-09-10 13:53:15,742 - INFO - 마포구 태종대: 식당 존재\n",
      "2024-09-10 13:53:15,760 - INFO - 추출된 href 값: https://place.map.kakao.com/11221487\n",
      "2024-09-10 13:53:15,775 - INFO - 추출된 rating 값: 4.4\n",
      "2024-09-10 13:53:15,793 - INFO - 추출된 review 값: 20\n",
      "2024-09-10 13:53:15,807 - INFO - 추출된 blog_review 값: 21\n",
      "2024-09-10 13:53:15,809 - INFO - 리뷰 존재\n",
      "2024-09-10 13:53:18,793 - INFO - 리뷰 ID 10225080는 이미 수집되었습니다. 건너뜁니다.\n",
      "식당 처리 중: 100%|██████████| 8/8 [01:06<00:00,  8.29s/it]\n",
      "2024-09-10 13:53:25,518 - INFO - 0 개의 리뷰가 성공적으로 삽입되었습니다.\n",
      "2024-09-10 13:53:25,519 - INFO - 데이터베이스 작업이 완료되었습니다.\n",
      "2024-09-10 13:53:25,620 - INFO - 0 개의 리뷰가 성공적으로 삽입되었습니다.\n",
      "2024-09-10 13:53:25,621 - INFO - 데이터베이스 작업이 완료되었습니다.\n",
      "2024-09-10 13:53:25,622 - INFO - 데이터 추출 및 삽입이 성공적으로 완료되었습니다.\n",
      "2024-09-10 13:53:25,623 - INFO - 프로그램 실행이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.getLogger('selenium').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('webdriver_manager').setLevel(logging.CRITICAL)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
